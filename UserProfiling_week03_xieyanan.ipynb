{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Project Week 03</h3>\n",
    "<p>名企BI班 week3 谢雅楠 20200912</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Thinking</h4>\n",
    "<p>1.如何使用用户标签来指导业务（如何提升业务）?<br/> → 在用户生命周期的三个阶段中，标签有不同的作用：A-获客:通过标签更精准的营销获取潜在客户; B-粘客:通过标签进行个性化推荐，搜索排序，场景运营等; C-留客:流失率预测，分析关键节点降低流失率。</p>\n",
    "<p>2.如果给你一堆用户数据，没有打标签。你该如何处理（如何打标签）？<br/> → 通过聚类方法，对用户画像进行profile learning，同时对item提取标签，从而完成基于标签的召回。</p>\n",
    "<p>3.准确率和精确率有何不同（评估指标）<br/> → 准确率 accuracy = (TP+TN)/(TP+FP+TN+FN)<br/> → 精确率 precision = TP/(TP+FN)</p>\n",
    "<p>4.如果你使用大众点评，想要给某个餐厅打标签。这时系统可以自动提示一些标签，你会如何设计（标签推荐)<br/> → 当用户u给物品i打标签时，可以给用户推荐和物品i相关的标签， 方法:\n",
    "方法1:给用户u推荐整个系统最热门的标签;\n",
    "方法2:给用户u推荐物品i上最热门的标签;\n",
    "方法3:给用户u推荐他自己经常使用的标签;\n",
    "将方法2和3进行加权融合，生成最终的标签推荐结果。</p>\n",
    "<h4>Action 1 针对Delicious数据集，对SimpleTagBased算法进行改进（使用NormTagBased、TagBased-TFIDF算法)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始数据加载...\n",
      "数据集大小为 437593.\n",
      "设置tag的人数 1867.\n",
      "数据加载完成\n",
      "\n",
      "训练集样本数 1860, 测试集样本数 1793\n",
      "user_tags, tag_items, user_items初始化完成.\n",
      "user_tags大小 1860, tag_items大小 36884, user_items大小 1860\n",
      "推荐结果评估\n",
      "  N        精确率        召回率\n",
      "  5      1.008%      0.431%\n",
      " 10      0.761%      0.652%\n",
      " 20      0.549%      0.940%\n",
      " 40      0.402%      1.376%\n",
      " 60      0.328%      1.687%\n",
      " 80      0.297%      2.033%\n",
      "100      0.269%      2.306%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import operator\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"./user_taggedbookmarks-timestamps.dat\"\n",
    "# 字典类型，保存了user对item的tag，即{userid: {item1:[tag1, tag2], ...}}\n",
    "records = {}\n",
    "# 训练集，测试集\n",
    "train_data = dict()\n",
    "test_data = dict()\n",
    "# 用户标签，商品标签\n",
    "user_tags = dict()\n",
    "tag_items = dict()\n",
    "user_items = dict()\n",
    "# 增加一些dict\n",
    "item_tags = dict()\n",
    "tag_users = dict()\n",
    "item_users = dict()\n",
    "\n",
    "# 使用测试集，计算准确率和召回率\n",
    "def precisionAndRecall(N):\n",
    "    hit = 0\n",
    "    h_recall = 0\n",
    "    h_precision = 0\n",
    "    for user,items in test_data.items():\n",
    "        if user not in train_data:\n",
    "            continue\n",
    "        # 获取Top-N推荐列表\n",
    "        rank = recommend(user, N)\n",
    "        for item,rui in rank:\n",
    "            if item in items:\n",
    "                hit = hit + 1\n",
    "        h_recall = h_recall + len(items)\n",
    "        h_precision = h_precision + N\n",
    "    #print('一共命中 %d 个, 一共推荐 %d 个, 用户设置tag总数 %d 个' %(hit, h_precision, h_recall))\n",
    "    # 返回准确率 和 召回率\n",
    "    return (hit/(h_precision*1.0)), (hit/(h_recall*1.0))\n",
    "\n",
    "# 对用户user推荐Top-N\n",
    "def recommend(user, N):\n",
    "    recommend_items=dict()\n",
    "    # 对Item进行打分，分数为所有的（用户对某标签使用的次数 wut, 乘以 商品被打上相同标签的次数 wti）之和\n",
    "    tagged_items = user_items[user]     \n",
    "    for tag, wut in user_tags[user].items():\n",
    "        #print(self.user_tags[user].items())\n",
    "        for item, wti in tag_items[tag].items():\n",
    "            if item in tagged_items:\n",
    "                continue\n",
    "            # NormTagBased-1 \n",
    "            norm = len(tag_users[tag].items()) * len(user_tags[user].items())\n",
    "            # TagBased-IDF\n",
    "            norm =  math.log(len(tag_users[tag].items()) + 1)\n",
    "            \n",
    "            #print('wut = %s, wti = %s' %(wut, wti))\n",
    "            if item not in recommend_items:\n",
    "                recommend_items[item] = wut * wti / norm\n",
    "            else:\n",
    "                recommend_items[item] = recommend_items[item] + wut * wti / norm\n",
    "    return sorted(recommend_items.items(), key=operator.itemgetter(1), reverse=True)[0:N]\n",
    "\n",
    "# 使用测试集，对推荐结果进行评估\n",
    "def testRecommend():\n",
    "    print(\"推荐结果评估\")\n",
    "    print(\"%3s %10s %10s\" % ('N',\"精确率\",'召回率'))\n",
    "    for n in [5,10,20,40,60,80,100]:\n",
    "        precision,recall = precisionAndRecall(n)\n",
    "        print(\"%3d %10.3f%% %10.3f%%\" % (n, precision * 100, recall * 100))\n",
    "        \n",
    "# 数据加载\n",
    "def load_data():\n",
    "    print(\"开始数据加载...\")\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    for i in range(len(df)):\n",
    "        uid = df['userID'][i]\n",
    "        iid = df['bookmarkID'][i]\n",
    "        tag = df['tagID'][i]\n",
    "        # 键不存在时，设置默认值{}\n",
    "        records.setdefault(uid,{})\n",
    "        records[uid].setdefault(iid,[])\n",
    "        records[uid][iid].append(tag)\n",
    "    print(\"数据集大小为 %d.\" % (len(df)))\n",
    "    print(\"设置tag的人数 %d.\" % (len(records)))\n",
    "    print(\"数据加载完成\\n\")\n",
    "\n",
    "# 将数据集拆分为训练集和测试集\n",
    "def train_test_split(ratio, seed=100):\n",
    "    random.seed(seed)\n",
    "    for u in records.keys():\n",
    "        for i in records[u].keys():\n",
    "            # ratio比例设置为测试集\n",
    "            if random.random()<ratio:\n",
    "                test_data.setdefault(u,{})\n",
    "                test_data[u].setdefault(i,[])\n",
    "                for t in records[u][i]:\n",
    "                    test_data[u][i].append(t)\n",
    "            else:\n",
    "                train_data.setdefault(u,{})\n",
    "                train_data[u].setdefault(i,[])\n",
    "                for t in records[u][i]:\n",
    "                    train_data[u][i].append(t)        \n",
    "    print(\"训练集样本数 %d, 测试集样本数 %d\" % (len(train_data),len(test_data)))\n",
    "\n",
    "# 设置矩阵 mat[index, item] = 1\n",
    "def addValueToMat(mat, index, item, value=1):\n",
    "    if index not in mat:\n",
    "        mat.setdefault(index,{})\n",
    "        mat[index].setdefault(item,value)\n",
    "    else:\n",
    "        if item not in mat[index]:\n",
    "            mat[index][item] = value\n",
    "        else:\n",
    "            mat[index][item] += value\n",
    "\n",
    "\n",
    "# 使用训练集，初始化user_tags, tag_items, user_items\n",
    "def initStat():\n",
    "    records=train_data\n",
    "    for u,items in records.items():\n",
    "        for i,tags in items.items():\n",
    "            for tag in tags:\n",
    "                #print tag\n",
    "                # 用户和tag的关系\n",
    "                addValueToMat(user_tags, u, tag, 1)\n",
    "                # tag和item的关系\n",
    "                addValueToMat(tag_items, tag, i, 1)\n",
    "                # 用户和item的关系\n",
    "                addValueToMat(user_items, u, i, 1)\n",
    "                # item和tag的关系\n",
    "                addValueToMat(item_tags, i, tag, 1)\n",
    "                # tag与用户的关系\n",
    "                addValueToMat(tag_users, tag, u, 1)\n",
    "                # item与用户的关系\n",
    "                addValueToMat(item_users, i, u, 1)\n",
    "\n",
    "\n",
    "    print(\"user_tags, tag_items, user_items初始化完成.\")\n",
    "    print(\"user_tags大小 %d, tag_items大小 %d, user_items大小 %d\" % (len(user_tags), len(tag_items), len(user_items)))\n",
    "\n",
    "# 数据加载\n",
    "load_data()\n",
    "# 训练集，测试集拆分，20%测试集\n",
    "train_test_split(0.2)\n",
    "initStat()\n",
    "testRecommend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Action 2 对Titanic数据进行清洗，建模并对乘客生存进行预测。使用之前介绍过的10种模型中的至少2种（包括TPOT）\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看数据信息：列名、非空个数、类型等\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "------------------------------\n",
      "查看数据摘要\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "------------------------------\n",
      "查看离散数据分布\n",
      "                              Name   Sex  Ticket        Cabin Embarked\n",
      "count                          891   891     891          204      889\n",
      "unique                         891     2     681          147        3\n",
      "top     Leitch, Miss. Jessie Wills  male  347082  C23 C25 C27        S\n",
      "freq                             1   577       7            4      644\n",
      "------------------------------\n",
      "查看前5条数据\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "------------------------------\n",
      "查看后5条数据\n",
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "886          887         0       2                     Montvila, Rev. Juozas   \n",
      "887          888         1       1              Graham, Miss. Margaret Edith   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889          890         1       1                     Behr, Mr. Karl Howell   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
      "887  female  19.0      0      0      112053  30.00   B42        S  \n",
      "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
      "889    male  26.0      0      0      111369  30.00  C148        C  \n",
      "890    male  32.0      0      0      370376   7.75   NaN        Q  \n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "特征值\n",
      "     Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
      "0         3    male  22.000000      1      0   7.2500        S\n",
      "1         1  female  38.000000      1      0  71.2833        C\n",
      "2         3  female  26.000000      0      0   7.9250        S\n",
      "3         1  female  35.000000      1      0  53.1000        S\n",
      "4         3    male  35.000000      0      0   8.0500        S\n",
      "..      ...     ...        ...    ...    ...      ...      ...\n",
      "886       2    male  27.000000      0      0  13.0000        S\n",
      "887       1  female  19.000000      0      0  30.0000        S\n",
      "888       3  female  29.699118      1      2  23.4500        S\n",
      "889       1    male  26.000000      0      0  30.0000        C\n",
      "890       3    male  32.000000      0      0   7.7500        Q\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "['Age', 'Embarked=C', 'Embarked=Q', 'Embarked=S', 'Fare', 'Parch', 'Pclass', 'Sex=female', 'Sex=male', 'SibSp']\n"
     ]
    }
   ],
   "source": [
    "## 数据清洗\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# 数据加载\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "# 数据探索\n",
    "# 查看train_data信息\n",
    "#pd.set_option('display.max_columns', None) #显示所有列\n",
    "print('查看数据信息：列名、非空个数、类型等')\n",
    "print(train_data.info())\n",
    "print('-'*30)\n",
    "print('查看数据摘要')\n",
    "print(train_data.describe())\n",
    "print('-'*30)\n",
    "print('查看离散数据分布')\n",
    "print(train_data.describe(include=['O']))\n",
    "print('-'*30)\n",
    "print('查看前5条数据')\n",
    "print(train_data.head())\n",
    "print('-'*30)\n",
    "print('查看后5条数据')\n",
    "print(train_data.tail())\n",
    "\n",
    "# 使用平均年龄来填充年龄中的nan值\n",
    "train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].mean(),inplace=True)\n",
    "# 使用票价的均值填充票价中的nan值\n",
    "train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)\n",
    "\n",
    "print(train_data['Embarked'].value_counts())\n",
    "# 使用登录最多的港口来填充登录港口的nan值\n",
    "train_data['Embarked'].fillna('S', inplace=True)\n",
    "test_data['Embarked'].fillna('S',inplace=True)\n",
    "# 特征选择\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data['Survived']\n",
    "test_features = test_data[features]\n",
    "print('特征值')\n",
    "print(train_features)\n",
    "\n",
    "dvec=DictVectorizer(sparse=False)\n",
    "train_features=dvec.fit_transform(train_features.to_dict(orient='record'))\n",
    "print(dvec.feature_names_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score准确率为 0.9820\n",
      "cross_val_score准确率为 0.7790\n"
     ]
    }
   ],
   "source": [
    "## 方法1 使用ID3决策树\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 构造ID3决策树\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "# 决策树训练\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "test_features=dvec.transform(test_features.to_dict(orient='record'))\n",
    "# 决策树预测\n",
    "pred_labels = clf.predict(test_features)\n",
    "\n",
    "# 得到决策树准确率(基于训练集)\n",
    "acc_decision_tree = round(clf.score(train_features, train_labels), 6)\n",
    "print(u'score准确率为 %.4lf' % acc_decision_tree)\n",
    "\n",
    "# 使用K折交叉验证 统计决策树准确率\n",
    "print(u'cross_val_score准确率为 %.4lf' % np.mean(cross_val_score(clf, train_features, train_labels, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 方法2 使用TPOT\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tpot import TPOTClassifier\n",
    "data = train_data\n",
    "feature_lst = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "features = data[feature_lst]\n",
    "labels = train_data['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.75, test_size=0.25)\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2) \n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_titanic_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
