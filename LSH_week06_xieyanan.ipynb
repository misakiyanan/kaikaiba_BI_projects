{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Week 06\n",
    "名企BI班 week05 谢雅楠 20201003"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking\n",
    "1. 什么是近似最近邻查找，常用的方法有哪些？  \n",
    "近似最近邻检索，是在牺牲可接受范围内的精度的情况下的最近邻查找，因为是线性复杂度，相比KNN可以提高检索效率，用于大规模数据。  \n",
    "常用方法有LSH(locality-sensitive hashing)，MinHashLSH、SimHash\n",
    "  \n",
    "2. 为什么两个集合的minhash值相同的概率等于这两个集合的Jaccard相似度?  \n",
    "设集合S1和S2，那么这两列所在的行有下面3种类型：\n",
    "S1和S2的值都为1，记为X； 只有一个值为1，另一个值为0，记为Y；S1和S2的值都为0，记为Z。  \n",
    "S1和S2交集的元素个数为x，并集的元素个数为x+y，  \n",
    "所以sim(S1,S2) = Jaccard(S1,S2) = x/(x+y)。  \n",
    "h(S1)=h(S2)的概率为从上往下扫描，在碰到Y行之前碰到X行的概率，x/(x+y)。  \n",
    "所以两个集合的minhash值相同的概率等于这两个集合的Jaccard相似度。  \n",
    "ref. https://www.cnblogs.com/sddai/p/6110704.html\n",
    "  \n",
    "3. SimHash在计算文档相似度的作用是怎样的？  \n",
    "SimHash得到每篇文档的指纹，通过计算每两篇文档之间的Hamming距离，如果在3以内，可以认为文档相似度较高。\n",
    "\n",
    "4. 为什么YouTube采用期望观看时间作为评估指标？  \n",
    "常用的CTR指标对于视频搜索具有一定的欺骗性，点击了不一定观看，观看时长反应喜爱程度，所以作者提出采用期望观看时间作为评估指标。\n",
    "ref.https://blog.csdn.net/u012102306/article/details/79889609"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action 1\n",
    "使用MinHashLSHForest对微博新闻句子进行检索 weibo.txt  \n",
    "针对某句话进行Query，查找Top-3相似的句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSH, MinHashLSHForest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import jieba.posseg as pseg\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in file\n",
    "f = open('./weibos.txt', 'r', encoding='utf-8')\n",
    "text = f.read()\n",
    "# split\n",
    "sentences = re.split('[。！？]', text.replace('\\n', ''))  ### \\n end mark\n",
    "if sentences[len(sentences)-1] == '':\n",
    "    sentences.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "stop = [line.strip().decode('utf-8') for line in open('stopword.txt').readlines()]\n",
    "\n",
    "# get item string\n",
    "def get_item_str(item_text):\n",
    "    item_str = \"\" \n",
    "    item=(pseg.cut(item_text)) \n",
    "    # delete stop words\n",
    "    for i in list(item):\n",
    "        if i.word not in list(stop):  \n",
    "            item_str += i.word \n",
    "            item_str += \" \"\n",
    "    return item_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document list\n",
    "documents = []\n",
    "for item_text in sentences:\n",
    "    item_str = get_item_str(item_text)\n",
    "    documents.append(item_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create minHash\n",
    "def get_minhash(item_str):\n",
    "    temp = MinHash()\n",
    "    for d in item_str:\n",
    "        temp.update(d.encode('utf8'))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LSH Forest\n",
    "minhash_list = []\n",
    "forest = MinHashLSHForest()\n",
    "for i in range(len(documents)):\n",
    "    temp = get_minhash(documents[i])\n",
    "    minhash_list.append(temp)\n",
    "    forest.add(i, temp)\n",
    "# create index for keys for query\n",
    "forest.index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.75 ​国足输给叙利亚之后，里皮辞职\n",
      "4 0.2265625 ​据了解，无论中国足协态度如何，里皮其实在宣布请辞同时已经去意已决\n",
      "37 0.484375 国足昨晚1-2输给叙利亚，赛后主帅里皮宣布辞职\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    query_statement = '里皮在国足输给叙利亚之后决定辞职'\n",
    "    # 1. get strings of query statemtent\n",
    "    item_str = get_item_str(query_statement)\n",
    "    # 2. create minHash\n",
    "    minhash_query = get_minhash(item_str)\n",
    "    # 3. query in forest\n",
    "    result = forest.query(minhash_query, 3)\n",
    "    for i in range(len(result)):\n",
    "        print(result[i], minhash_query.jaccard(minhash_list[result[i]]), documents[result[i]].replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
